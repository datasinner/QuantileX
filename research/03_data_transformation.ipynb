{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/c5367983/Desktop/Projects/QuantileX/research'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class DataTransformationConfig:\n",
    "    root_dir: Path\n",
    "    data_path: Path\n",
    "    assets_type: str\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.constants import *\n",
    "from src.utils.common import read_yaml, create_directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfigurationManager:\n",
    "    def __init__(\n",
    "        self, config_filepath=CONFIG_FILE_PATH, params_filepath=PARAMS_FILE_PATH\n",
    "    ):\n",
    "        self.config = read_yaml(config_filepath)\n",
    "        self.params = read_yaml(params_filepath)\n",
    "\n",
    "        create_directories([self.config.artifacts_root])\n",
    "    \n",
    "    def get_data_transformation_config(self) -> DataTransformationConfig:\n",
    "        config = self.config.data_transformation\n",
    "\n",
    "        create_directories([config.root_dir])\n",
    "\n",
    "        data_transformation_config = DataTransformationConfig(\n",
    "            root_dir= config.root_dir,\n",
    "            data_path = config.data_path + \"/\" + self.config.data_ingestion.assets_type ,\n",
    "            assets_type =config.assets_type\n",
    "        )\n",
    "\n",
    "        return data_transformation_config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from src.logging import logger\n",
    "from datetime import datetime\n",
    "from datasets import load_dataset, load_from_disk\n",
    "from ta import add_all_ta_features\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataTransformation:\n",
    "    def __init__(self, config: DataTransformationConfig):\n",
    "        self.config = config\n",
    "        self.df = pd.read_csv(self.config.data_path + \"/\" + self.config.assets_type + \"_2015-01-01_\" +datetime.now().strftime('%Y-%m-%d') + \".csv\")\n",
    "        self.preprocessed_df = None\n",
    "        self.continuous_cols = []\n",
    "        self.categorical_cols = []\n",
    "\n",
    "    def preprocess(self):\n",
    "        preprocessed_df = self.df.copy()\n",
    "        preprocessed_df['Date'] = pd.to_datetime(preprocessed_df['Date'])\n",
    "        preprocessed_df = preprocessed_df.set_index('Date')\n",
    "        preprocessed_df['Timestamp'] = preprocessed_df.index.astype(np.int64)//10**9\n",
    "        preprocessed_df['Year'] = preprocessed_df.index.year\n",
    "        preprocessed_df['Month'] = preprocessed_df.index.month\n",
    "        preprocessed_df['Day'] = preprocessed_df.index.day\n",
    "        preprocessed_df['DayOfWeek'] = preprocessed_df.index.dayofweek\n",
    "        preprocessed_df['MA7_Close'] = preprocessed_df['Close'].rolling(window=7).mean()\n",
    "        preprocessed_df['MA30_Close'] = preprocessed_df['Close'].rolling(window=30).mean()\n",
    "        preprocessed_df['Lag1_Close'] = preprocessed_df['Close'].shift(1)\n",
    "        preprocessed_df['Volume_Change_Pct'] = preprocessed_df['Volume'].pct_change()\n",
    "        preprocessed_df['target'] = np.where(preprocessed_df['Close'] < preprocessed_df['Open'], 0, 1)\n",
    "        preprocessed_df['target'] = preprocessed_df['target'].shift(-1)\n",
    "\n",
    "        preprocessed_df_with_ta = add_all_ta_features(preprocessed_df, open=\"Open\", high=\"High\", low=\"Low\", close=\"Close\", volume=\"Volume\")\n",
    "        \n",
    "        preprocessed_df_with_ta = self.drop_cols(preprocessed_df_with_ta)\n",
    "        \n",
    "        self.preprocessed_df = preprocessed_df_with_ta\n",
    "\n",
    "    def identify_column_type(self, threshold_unique = 100):\n",
    "             \n",
    "        for col in self.preprocessed_df.columns:\n",
    "            unique_values = self.preprocessed_df[col].nunique(dropna=False)\n",
    "            has_floats = any(self.preprocessed_df[col].apply(lambda x: isinstance(x,float)))\n",
    "            if has_floats:\n",
    "                self.continuous_cols.append(col)\n",
    "                continue\n",
    "            if unique_values <= threshold_unique:\n",
    "                self.categorical_cols.append(col)\n",
    "            else:\n",
    "                self.continuous_cols.append(col)\n",
    "\n",
    "    def impute_missing_values(self):\n",
    "        for continuous_col in self.continuous_cols:\n",
    "            self.preprocessed_df[continuous_col].fillna(self.preprocessed_df[continuous_col].mean(), inplace = True)\n",
    "        for cotegorical_col in self.categorical_cols:\n",
    "            mode_value = self.preprocessed_df[cotegorical_col].mode()[0]\n",
    "            self.preprocessed_df[cotegorical_col].fillna(mode_value, inplace=True)\n",
    "   \n",
    "    def drop_cols(self, df):\n",
    "        for column in df.columns:\n",
    "            max_count = df[column].value_counts().max()\n",
    "            if max_count/len(df) > 0.8:\n",
    "                df.drop(column, axis=1, inplace=True)\n",
    "        return df\n",
    "    \n",
    "    def save_data(self):\n",
    "        if not os.path.exists(self.config.root_dir):\n",
    "            os.makedirs(self.config.root_dir)\n",
    "            \n",
    "        filepath = os.path.join(self.config.root_dir, f\"{self.config.assets_type}.csv\")\n",
    "        self.preprocessed_df.to_csv(filepath, index=True)\n",
    "        print(f\"Data saved successfully to {filepath}\")\n",
    "\n",
    "    \n",
    "    def convert(self):\n",
    "        self.preprocess()\n",
    "        self.identify_column_type()\n",
    "        self.impute_missing_values()\n",
    "        self.save_data()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-02-25 20:20:28,918: INFO: common: yaml file: config/config.yaml loaded successfully]\n",
      "[2024-02-25 20:20:28,919: INFO: common: yaml file: params.yaml loaded successfully]\n",
      "[2024-02-25 20:20:28,920: INFO: common: Created directory at: artifacts]\n",
      "[2024-02-25 20:20:28,920: INFO: common: Created directory at: artifacts/data_transformation]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/c5367983/anaconda3/envs/quantilex/lib/python3.12/site-packages/ta/trend.py:1030: FutureWarning: Series.__setitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To set a value by position, use `ser.iloc[pos] = value`\n",
      "  self._psar[i] = high2\n",
      "/var/folders/9n/3_zg_58x1hl5lwsdqj1dy0tm0000gn/T/ipykernel_41305/550700355.py:46: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  self.preprocessed_df[continuous_col].fillna(self.preprocessed_df[continuous_col].mean(), inplace = True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved successfully to artifacts/data_transformation/BTC-USD.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/9n/3_zg_58x1hl5lwsdqj1dy0tm0000gn/T/ipykernel_41305/550700355.py:49: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  self.preprocessed_df[cotegorical_col].fillna(mode_value, inplace=True)\n",
      "/var/folders/9n/3_zg_58x1hl5lwsdqj1dy0tm0000gn/T/ipykernel_41305/550700355.py:49: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  self.preprocessed_df[cotegorical_col].fillna(mode_value, inplace=True)\n",
      "/var/folders/9n/3_zg_58x1hl5lwsdqj1dy0tm0000gn/T/ipykernel_41305/550700355.py:49: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  self.preprocessed_df[cotegorical_col].fillna(mode_value, inplace=True)\n",
      "/var/folders/9n/3_zg_58x1hl5lwsdqj1dy0tm0000gn/T/ipykernel_41305/550700355.py:49: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  self.preprocessed_df[cotegorical_col].fillna(mode_value, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    config = ConfigurationManager()\n",
    "    data_transformation_config = config.get_data_transformation_config()\n",
    "    data_transformation = DataTransformation(config=data_transformation_config)\n",
    "    data_transformation.convert()\n",
    "except Exception as e:\n",
    "    raise e\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "quantilex",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
